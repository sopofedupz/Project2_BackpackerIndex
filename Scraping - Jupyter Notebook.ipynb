{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set executable path and initialize Chrome browser\n",
    "\n",
    "# MAC\n",
    "# executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "\n",
    "# Windows\n",
    "executable_path = {\"executable_path\": \"chromedriver.exe\"}\n",
    "\n",
    "browser = Browser(\"chrome\", **executable_path, headless=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the backpacker website\n",
    "url = \"https://www.priceoftravel.com/world-cities-by-price-backpacker-index/\"\n",
    "browser.visit(url)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# Find all cities in top list\n",
    "top_cities_html = browser.html\n",
    "top_cities_soup = bs(top_cities_html, \"html.parser\")\n",
    "\n",
    "top_cities = top_cities_soup.find('div', class_ = \"bpiidx_list\").find_all('a', href=True)\n",
    "daily_total = top_cities_soup.find('div', class_ = \"bpiidx_list\").find_all('div', class_=\"bpidx price\")\n",
    "\n",
    "# create a dict for each set of information type\n",
    "city_facts_dict = {}\n",
    "transport_dict = {}\n",
    "food_drinks_dict = {}\n",
    "temp_prcp_dict = {}\n",
    "hotel_dict = {}\n",
    "hostel_dict = {}\n",
    "intro_dict = {}\n",
    "\n",
    "# create all the lists that we need to store the information\n",
    "places_list = []\n",
    "rank_list = []\n",
    "daily_total_list = []\n",
    "population_list = []\n",
    "metro_list = []\n",
    "timezone_list = []\n",
    "currency_list = []\n",
    "airport_list = []\n",
    "transport_city_list = []\n",
    "transport_mode_list = []\n",
    "transport_upper_price_list = []\n",
    "transport_lower_price_list = []\n",
    "food_city_list = []\n",
    "food_type_list = []\n",
    "food_desc_list = []\n",
    "food_upper_price_list = []\n",
    "food_lower_price_list = []\n",
    "temp_prcp_cityList = []\n",
    "month_list = []\n",
    "high_temp_list = []\n",
    "low_temp_list = []\n",
    "prcp_inch_list = []\n",
    "hotel_cityList = []\n",
    "hotel_ratingsList = []\n",
    "hotel_upper_priceList = []\n",
    "hotel_lower_priceList = []\n",
    "hostel_cityList = []\n",
    "hostel_upper_priceList = []\n",
    "hostel_lower_priceList = []\n",
    "intro_p1 = []\n",
    "intro_p2 = []\n",
    "intro_p3 = []\n",
    "intro_p4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in range(0,len(top_cities)):\n",
    "        \n",
    "    city_country_name = top_cities[city].text.replace(\"\\n\",\" \").strip()\n",
    "    places_list.append(city_country_name)\n",
    "    \n",
    "    # get daily total\n",
    "    city_daily_total = daily_total[city]\n",
    "    city_daily_total = city_daily_total.text.replace(\"\\n\",\" \").strip()\n",
    "    city_daily_total = city_daily_total.split(\"$\")\n",
    "    city_daily_total = city_daily_total[1]\n",
    "    daily_total_list.append(city_daily_total)\n",
    "\n",
    "    # get the links to each of the top cities page\n",
    "    top_city = top_cities[city]\n",
    "    top_cities_link = top_city.get_attribute_list('href')[0]\n",
    "    browser.visit(top_cities_link)\n",
    "\n",
    "    #######################\n",
    "    # Scrape facts table\n",
    "    #######################\n",
    "    try:\n",
    "        # getting the city facts\n",
    "        browser_html = browser.html\n",
    "        browser_soup = bs(browser_html, \"html.parser\")\n",
    "        \n",
    "        population = browser_soup.find(\"table\", class_ = \"col city-facts\").find_all('td', class_ = \"white\")[0]\n",
    "        population = population.text.replace(\"\\n\",\" \").strip()\n",
    "        population = float(population.replace(',',''))\n",
    "\n",
    "        metro = browser_soup.find(\"table\", class_ = \"col city-facts\").find_all('td', class_ = \"white\")[1]\n",
    "        metro = metro.text.replace(\"\\n\",\" \").strip()\n",
    "        metro = float(metro.replace(',',''))\n",
    "\n",
    "        timezone = browser_soup.find(\"table\", class_ = \"col city-facts\").find_all('td', class_ = \"white\")[2]\n",
    "        timezone = timezone.text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "        currency = browser_soup.find(\"table\", class_ = \"col city-facts\").find_all('td', class_ = \"white\")[3]\n",
    "        currency = currency.text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "        airport = browser_soup.find(\"table\", class_ = \"col city-facts\").find_all('td', class_ = \"white\")[4]\n",
    "        airport = airport.text.replace(\"\\n\",\" \").strip()\n",
    "          \n",
    "    except AttributeError:\n",
    "        population = \"\"\n",
    "        metro = \"\"\n",
    "        timezone = \"\"\n",
    "        currency = \"\"\n",
    "        airport = \"\"\n",
    "\n",
    "    # append data to lists\n",
    "    rank_list.append(city+1)\n",
    "    population_list.append(population)\n",
    "    metro_list.append(metro)\n",
    "    timezone_list.append(timezone)\n",
    "    currency_list.append(currency)\n",
    "    airport_list.append(airport)\n",
    "    \n",
    "    print(f\"{city+1}\")\n",
    "    \n",
    "    ########################\n",
    "    # Scrape intro paragraph\n",
    "    ########################\n",
    "    try:\n",
    "        # getting the city facts\n",
    "        browser_html = browser.html\n",
    "        browser_soup = bs(browser_html, \"html.parser\")\n",
    "        \n",
    "        intro1 = browser_soup.find(id=\"content\").find_all('p')[0]\n",
    "        intro1 = intro1.text.replace(\"\\n\",\" \").strip()\n",
    "        \n",
    "        intro2 = browser_soup.find(id=\"content\").find_all('p')[1]\n",
    "        intro2 = intro2.text.replace(\"\\n\",\" \").strip()\n",
    "        \n",
    "        intro3 = browser_soup.find(id=\"content\").find_all('p')[2]\n",
    "        intro3 = intro3.text.replace(\"\\n\",\" \").strip()\n",
    "        \n",
    "        intro4 = browser_soup.find(id=\"content\").find_all('p')[3]\n",
    "        intro4 = intro4.text.replace(\"\\n\",\" \").strip()\n",
    "        \n",
    "    except:\n",
    "        # getting the city facts\n",
    "        browser_html = browser.html\n",
    "        browser_soup = bs(browser_html, \"html.parser\")\n",
    "        \n",
    "        intro1 = browser_soup.find(id=\"content\").find_all('p')[0]\n",
    "        intro1 = intro1.text.replace(\"\\n\",\" \").strip()\n",
    "        \n",
    "        intro2 = browser_soup.find(id=\"content\").find_all('p')[1]\n",
    "        intro2 = intro2.text.replace(\"\\n\",\" \").strip()\n",
    "        \n",
    "        intro3 = browser_soup.find(id=\"content\").find_all('p')[2]\n",
    "        intro3 = intro3.text.replace(\"\\n\",\" \").strip()\n",
    "        \n",
    "        intro4 = \"empty\"\n",
    "        \n",
    "    # append data to lists\n",
    "    intro_p1.append(intro1)\n",
    "    intro_p2.append(intro2)\n",
    "    intro_p3.append(intro3)\n",
    "    intro_p4.append(intro4)\n",
    "    \n",
    "    print(f\"#{city+1}: {city_country_name}; {intro4}\")\n",
    "    \n",
    "    ################################\n",
    "    # Scrape transportation prices\n",
    "    ################################\n",
    "\n",
    "    try:\n",
    "        # Gather transportation information\n",
    "        \n",
    "        browser_html = browser.html\n",
    "        browser_soup = bs(browser_html, \"html.parser\")\n",
    "        \n",
    "        transport_table = browser_soup.find(\"table\", class_ = \"fcol fcol-padding\").find_all('tr', class_ = \"border no-pad\")\n",
    "        \n",
    "        for transport in range(0,len(transport_table)):\n",
    "            \n",
    "            # get transport mode/type\n",
    "            transport_mode = transport_table[transport].find('td', class_=\"white\")\n",
    "            transport_mode = transport_mode.text.replace(\"\\n\",\" \").strip()\n",
    "            transport_mode_list.append(transport_mode)\n",
    "\n",
    "            # get transportation price\n",
    "            transport_price = transport_table[transport].find('td', class_=\"white2\")\n",
    "            transport_price = transport_price.text.replace(\"\\n\",\" \").strip()\n",
    "            \n",
    "            # split the price range into upper and lower range\n",
    "            try:\n",
    "                transport_price_range = transport_price.split(\" - \")\n",
    "                lower_price = transport_price_range[0]\n",
    "                upper_price = transport_price_range[1]\n",
    "            except:\n",
    "                lower_price = transport_price\n",
    "                upper_price = transport_price\n",
    "                \n",
    "            transport_lower_price_list.append(lower_price)\n",
    "            transport_upper_price_list.append(upper_price)\n",
    "            \n",
    "            # get country list\n",
    "            transport_city_list.append(city_country_name)\n",
    "                                           \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    ################################\n",
    "    # Scrape food and drink prices\n",
    "    ################################\n",
    "    \n",
    "    # Gather food information\n",
    "    try:\n",
    "        browser_html = browser.html\n",
    "        browser_soup = bs(browser_html, \"html.parser\")\n",
    "        \n",
    "        food_table = browser_soup.find_all(\"table\", class_ = \"fcol fcol-padding\")[1]\n",
    "        food_table = food_table.find_all('td', class_ = \"white\")\n",
    "        \n",
    "        for food in range(0,len(food_table),3):  \n",
    "\n",
    "            # get food type\n",
    "            food_type = food_table[food].text.replace(\"\\n\",\" \").strip()\n",
    "            food_type_list.append(food_type)\n",
    "\n",
    "            # get description\n",
    "            food_desc = food_table[food+1].text.replace(\"\\n\",\" \").strip()\n",
    "            food_desc_list.append(food_desc)\n",
    "\n",
    "            # get food price\n",
    "            food_price = food_table[food+2].text.replace(\"\\n\",\" \").strip()\n",
    "            \n",
    "            # split the range and put into lower and upper price range\n",
    "            try:\n",
    "                food_price_range = food_price.split(\" - \")\n",
    "                lower_price = food_price_range[0]\n",
    "                upper_price = food_price_range[1]\n",
    "            except:\n",
    "                lower_price = food_price\n",
    "                upper_price = food_price\n",
    "                \n",
    "            food_lower_price_list.append(lower_price)\n",
    "            food_upper_price_list.append(upper_price)\n",
    "            \n",
    "            # get country list\n",
    "            food_city_list.append(city_country_name)\n",
    "\n",
    "    except IndexError:\n",
    "        pass\n",
    "        \n",
    "    ########################################\n",
    "    # Scrape temperature & precipitation\n",
    "    ########################################\n",
    "    \n",
    "    try:\n",
    "        browser_html = browser.html\n",
    "        browser_soup = bs(browser_html, \"html.parser\")\n",
    "        \n",
    "        table = browser_soup.find(\"table\", class_ = \"center-table weather-tab\").find_all(\"td\")\n",
    "\n",
    "        # Gather temperature and precipitation information\n",
    "        for data in range(0,len(table),4):\n",
    "\n",
    "            # get month\n",
    "            month = table[data].text.replace(\"\\n\",\" \").strip()\n",
    "            month_list.append(month)\n",
    "\n",
    "            # get high temp\n",
    "            hi_temp = table[data+1].text.replace(\"\\n\",\" \").strip()\n",
    "            high_temp_list.append(hi_temp)\n",
    "\n",
    "            # get low temp\n",
    "            lo_temp = table[data+2].text.replace(\"\\n\",\" \").strip()\n",
    "            low_temp_list.append(lo_temp)\n",
    "\n",
    "            # get precipitation in inches\n",
    "            prcp = table[data+3].text.replace(\"\\n\",\" \").strip()\n",
    "            prcp_inch_list.append(prcp)\n",
    "            \n",
    "            # get country list\n",
    "            temp_prcp_cityList.append(city_country_name)\n",
    "            \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    ########################################\n",
    "    # Scrape hotel and hostel information\n",
    "    ########################################\n",
    "    \n",
    "    try:\n",
    "        browser_html = browser.html\n",
    "        browser_soup = bs(browser_html, \"html.parser\")\n",
    "        \n",
    "        #################\n",
    "        # Hotel\n",
    "        #################\n",
    "        \n",
    "        hotel_table = browser_soup.find(\"table\", class_ = \"ratings\").find_all('td')\n",
    "                \n",
    "        # get hotel ratings\n",
    "        for i in range(1,6):\n",
    "            if i == 1:\n",
    "                stars = f\"{i}_star\"\n",
    "            else:\n",
    "                stars = f\"{i}_stars\"\n",
    "            hotel_ratingsList.append(stars)        \n",
    "        \n",
    "        for data in range(1,len(hotel_table),2):\n",
    "        \n",
    "            # get country list\n",
    "            hotel_cityList.append(city_country_name)\n",
    "            \n",
    "            # get hotel price        \n",
    "\n",
    "            hotel_price = hotel_table[data].text.replace(\"\\n\",\" \").strip()\n",
    "            \n",
    "            try:\n",
    "                hotel_price_list = hotel_price.split(\" - \")\n",
    "                hotel_lower_price = hotel_price_list[0]\n",
    "                hotel_upper_price = hotel_price_list[1]\n",
    "            except:\n",
    "                hotel_lower_price = hotel_price\n",
    "                hotel_upper_price = hotel_price\n",
    "                \n",
    "            hotel_lower_priceList.append(hotel_lower_price)\n",
    "            hotel_upper_priceList.append(hotel_upper_price)\n",
    "                                                  \n",
    "            # print to check scraping status\n",
    "            # print(f\"#{city+1}: {city_country_name}; {stars}: {hotel_lower_price} - {hotel_upper_price}\")\n",
    "        \n",
    "        ###########\n",
    "        # Hostel\n",
    "        ###########\n",
    "        \n",
    "        hostel_table = browser_soup.find(\"table\", class_ = \"ratings hostel-ratings\").find_all('td')\n",
    "        \n",
    "        hostel_price = hostel_table[1].text.replace(\"\\n\",\" \").strip()\n",
    "            \n",
    "        try:\n",
    "            hostel_price_list = hostel_price.split(\" - \")\n",
    "            hostel_lower_price = hostel_price_list[0]\n",
    "            hostel_upper_price = hostel_price_list[1]\n",
    "        except:\n",
    "            hostel_lower_price = hostel_price\n",
    "            hostel_upper_price = hostel_price\n",
    "\n",
    "        hostel_lower_priceList.append(hostel_lower_price)\n",
    "        hostel_upper_priceList.append(hostel_upper_price)\n",
    "        \n",
    "        # get country list\n",
    "        hostel_cityList.append(city_country_name)       \n",
    "\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# put into a dict\n",
    "###################\n",
    "\n",
    "# city facts table\n",
    "city_facts_dict['city_country'] = places_list\n",
    "city_facts_dict['rank'] = rank_list \n",
    "city_facts_dict['daily_total_value'] = daily_total_list\n",
    "city_facts_dict['population'] = population_list\n",
    "city_facts_dict['metro'] = metro_list\n",
    "city_facts_dict['timezone'] = timezone_list\n",
    "city_facts_dict['currency'] = currency_list\n",
    "city_facts_dict['airport'] = airport_list\n",
    "\n",
    "# intro table\n",
    "intro_dict['city_country'] = places_list\n",
    "intro_dict['intro_para1'] = intro_p1\n",
    "intro_dict['intro_para2'] = intro_p2 \n",
    "intro_dict['intro_para3'] = intro_p3 \n",
    "intro_dict['intro_para4'] = intro_p4 \n",
    "\n",
    "# transportation table\n",
    "transport_dict['city_country'] = transport_city_list\n",
    "transport_dict['transport_mode'] = transport_mode_list\n",
    "transport_dict['transport_lower_price'] = transport_lower_price_list\n",
    "transport_dict['transport_upper_price'] = transport_upper_price_list\n",
    "\n",
    "# food and drinks table\n",
    "food_drinks_dict['city_country'] = food_city_list\n",
    "food_drinks_dict['food_drinks_type'] = food_type_list\n",
    "food_drinks_dict['food_drinks_desc'] = food_desc_list\n",
    "food_drinks_dict['food_drinks_lower_price'] = food_lower_price_list\n",
    "food_drinks_dict['food_drinks_upper_price'] = food_upper_price_list\n",
    "\n",
    "# temperature and precipitation table\n",
    "temp_prcp_dict['city_country'] = temp_prcp_cityList\n",
    "temp_prcp_dict['month'] = month_list\n",
    "temp_prcp_dict['high_temp'] = high_temp_list\n",
    "temp_prcp_dict['low_temp'] = low_temp_list\n",
    "temp_prcp_dict['prcp_inch'] = prcp_inch_list\n",
    "\n",
    "# hotel pricing table\n",
    "hotel_dict['city_country'] = hotel_cityList\n",
    "hotel_dict['hotel_ratings'] = hotel_ratingsList\n",
    "hotel_dict['hotel_lower_price'] = hotel_lower_priceList\n",
    "hotel_dict['hotel_upper_price'] = hotel_upper_priceList\n",
    "\n",
    "# hostel pricing table\n",
    "hostel_dict['city_country'] = hostel_cityList\n",
    "hostel_dict['hostel_lower_price'] = hostel_lower_priceList\n",
    "hostel_dict['hostel_upper_price'] = hostel_upper_priceList\n",
    "\n",
    "##################################\n",
    "# put data into pandas dataframe\n",
    "##################################\n",
    "city_facts_df = pd.DataFrame.from_dict(city_facts_dict)\n",
    "transport_df = pd.DataFrame.from_dict(transport_dict)\n",
    "food_drinks_df = pd.DataFrame.from_dict(food_drinks_dict)\n",
    "temp_prcp_df = pd.DataFrame.from_dict(temp_prcp_dict)\n",
    "hotel_df = pd.DataFrame.from_dict(hotel_dict)\n",
    "hostel_df = pd.DataFrame.from_dict(hostel_dict)\n",
    "intro_df = pd.DataFrame.from_dict(intro_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to SQLite\n",
    "conn = sqlite3.connect('backpackers_index.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "# City Facts\n",
    "###################\n",
    "\n",
    "# replace \"-\" with \"\" and convert into float\n",
    "city_facts_df = city_facts_df.replace(\"-\", \"\")\n",
    "city_facts_df[\"daily_total_value\"] = pd.to_numeric(city_facts_df[\"daily_total_value\"])\n",
    "\n",
    "# Create table\n",
    "c.execute('CREATE TABLE CITY_FACTS (CITY_COUNTRY, RANK, DAILY_TOTAL_VALUE, POPULATION, METRO, TIMEZONE, CURRENCY, AIRPORT)')\n",
    "conn.commit()\n",
    "city_facts_df.to_sql('CITY_FACTS', conn, if_exists='replace', index = True)\n",
    "    \n",
    "# check if table in database is created\n",
    "\n",
    "c.execute('''  \n",
    "SELECT * FROM CITY_FACTS\n",
    "          ''')\n",
    "\n",
    "for row in c.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Intro Paragraph\n",
    "###################\n",
    "\n",
    "# Create table\n",
    "c.execute('CREATE TABLE INTRO (CITY_COUNTRY, INTRO1, INTRO2, INTRO3, INTRO4)')\n",
    "conn.commit()\n",
    "intro_df.to_sql('INTRO', conn, if_exists='replace', index = True)\n",
    "    \n",
    "# check if table in database is created\n",
    "\n",
    "c.execute('''  \n",
    "SELECT * FROM INTRO\n",
    "          ''')\n",
    "\n",
    "for row in c.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Transportation\n",
    "###################\n",
    "\n",
    "# replace \"-\" with \"\" and convert into float\n",
    "transport_df = transport_df.replace(\"-\", \"\")\n",
    "transport_df[\"transport_lower_price\"] = pd.to_numeric(transport_df[\"transport_lower_price\"])\n",
    "transport_df[\"transport_upper_price\"] = pd.to_numeric(transport_df[\"transport_upper_price\"])\n",
    "\n",
    "# Create table\n",
    "c.execute('CREATE TABLE TRANSPORTATION (CITY_COUNTRY, TRANSPORT_MODE, LOWER_PRICE, UPPER_PRICE)')\n",
    "conn.commit()\n",
    "transport_df.to_sql('TRANSPORTATION', conn, if_exists='replace', index = True)\n",
    "    \n",
    "# check if table in database is created\n",
    "\n",
    "c.execute('''  \n",
    "SELECT * FROM TRANSPORTATION\n",
    "          ''')\n",
    "\n",
    "for row in c.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Food and Drinks\n",
    "###################\n",
    "\n",
    "# replace \"-\" with \"\" and convert into float\n",
    "food_drinks_df = food_drinks_df.replace(\"-\", \"\")\n",
    "food_drinks_df[\"food_drinks_lower_price\"] = pd.to_numeric(food_drinks_df[\"food_drinks_lower_price\"])\n",
    "food_drinks_df[\"food_drinks_upper_price\"] = pd.to_numeric(food_drinks_df[\"food_drinks_upper_price\"])\n",
    "\n",
    "# Create table\n",
    "c.execute('CREATE TABLE FOOD_DRINKS (CITY_COUNTRY, FOOD_DRINKS_TYPE, FOOD_DRINKS_DESC, LOWER_PRICE, UPPER_PRICE)')\n",
    "conn.commit()\n",
    "food_drinks_df.to_sql('FOOD_DRINKS', conn, if_exists='replace', index = True)\n",
    "    \n",
    "# check if table in database is created\n",
    "\n",
    "c.execute('''  \n",
    "SELECT * FROM FOOD_DRINKS\n",
    "          ''')\n",
    "\n",
    "for row in c.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Temperature and Precipitation\n",
    "################################\n",
    "\n",
    "# replace \"-\" with \"\" and convert into float\n",
    "temp_prcp_df = temp_prcp_df.replace(\"-\", \"\")\n",
    "temp_prcp_df[\"high_temp\"] = pd.to_numeric(temp_prcp_df[\"high_temp\"])\n",
    "temp_prcp_df[\"low_temp\"] = pd.to_numeric(temp_prcp_df[\"low_temp\"])\n",
    "temp_prcp_df[\"prcp_inch\"] = pd.to_numeric(temp_prcp_df[\"prcp_inch\"])\n",
    "\n",
    "# Create table\n",
    "c.execute('CREATE TABLE TEMP_PRCP (CITY_COUNTRY, MONTH, HIGH_TEMP, LOW_TEMP, PRCP_INCH)')\n",
    "conn.commit()\n",
    "temp_prcp_df.to_sql('TEMP_PRCP', conn, if_exists='replace', index = True)\n",
    "    \n",
    "# check if table in database is created\n",
    "\n",
    "c.execute('''  \n",
    "SELECT * FROM TEMP_PRCP\n",
    "          ''')\n",
    "\n",
    "for row in c.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Hotel\n",
    "#########\n",
    "\n",
    "# replace \"-\" with \"\" and convert into float\n",
    "hotel_df = hotel_df.replace(\"-\", \"\")\n",
    "hotel_df[\"hotel_lower_price\"] = pd.to_numeric(hotel_df[\"hotel_lower_price\"])\n",
    "hotel_df[\"hotel_upper_price\"] = pd.to_numeric(hotel_df[\"hotel_upper_price\"])\n",
    "\n",
    "# Create table\n",
    "c.execute('CREATE TABLE HOTEL (CITY_COUNTRY, RATINGS, LOWER_PRICE, UPPER_PRICE)')\n",
    "conn.commit()\n",
    "hotel_df.to_sql('HOTEL', conn, if_exists='replace', index = True)\n",
    "    \n",
    "# check if table in database is created\n",
    "\n",
    "c.execute('''  \n",
    "SELECT * FROM HOTEL\n",
    "          ''')\n",
    "\n",
    "for row in c.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Hostel\n",
    "#########\n",
    "\n",
    "# replace \"-\" with \"\" and convert into float\n",
    "hostel_df = hostel_df.replace(\"-\", \"\")\n",
    "hostel_df[\"hostel_lower_price\"] = pd.to_numeric(hostel_df[\"hostel_lower_price\"])\n",
    "hostel_df[\"hostel_upper_price\"] = pd.to_numeric(hostel_df[\"hostel_upper_price\"])\n",
    "\n",
    "# Create table\n",
    "c.execute('CREATE TABLE HOSTEL (CITY_COUNTRY, LOWER_PRICE, UPPER_PRICE)')\n",
    "conn.commit()\n",
    "hostel_df.to_sql('HOSTEL', conn, if_exists='replace', index = True)\n",
    "    \n",
    "# check if table in database is created\n",
    "\n",
    "c.execute('''  \n",
    "SELECT * FROM HOSTEL\n",
    "          ''')\n",
    "\n",
    "for row in c.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Getting the coordinates for each city\n",
    "##################################################\n",
    "\n",
    "locator = Nominatim(user_agent=\"myGeocoder\")\n",
    "\n",
    "top_places = {}\n",
    "latitude_list = []\n",
    "longitude_list = []\n",
    "counter = 1\n",
    "\n",
    "for place in places_list:   \n",
    "    try:\n",
    "        location = locator.geocode(place)        \n",
    "        \n",
    "        latitude = location.latitude \n",
    "        longitude = location.longitude\n",
    "        \n",
    "        print(f\"{counter}. Place: {place} - Latitude: {latitude} & Longitude: {longitude}\")\n",
    "        counter += 1\n",
    "    \n",
    "    except:\n",
    "        latitude = \"\"        \n",
    "        longitude = \"\"\n",
    "\n",
    "        print(f\"{counter}. Place: {place} - Latitude and Longitude not found!\")\n",
    "        counter += 1\n",
    "    \n",
    "    latitude_list.append(latitude)        \n",
    "    longitude_list.append(longitude)    \n",
    "    \n",
    "top_places['city_country'] = places_list\n",
    "top_places['lat'] = latitude_list\n",
    "top_places['lon'] = longitude_list\n",
    "\n",
    "# put data into pandas dataframe\n",
    "coords_df = pd.DataFrame(top_places, columns= ['city_country', 'lat', 'lon'])\n",
    "\n",
    "# check if any city doesn't have a coord\n",
    "empty_coords = coords_df[coords_df['lat']==\"\"]\n",
    "print(empty_coords)\n",
    "\n",
    "# enter coords for San Pedro (Ambergris Caye), Belize\n",
    "coords_df.loc[coords_df['city_country'] == \"San Pedro (Ambergris Caye), Belize\", 'lat'] = 18.0083682999\n",
    "coords_df.loc[coords_df['city_country'] == \"San Pedro (Ambergris Caye), Belize\", 'lon'] = -87.9252862988\n",
    "\n",
    "# check if data were correctly entered\n",
    "coords_df.loc[coords_df['city_country'] == \"San Pedro (Ambergris Caye), Belize\"]\n",
    "\n",
    "# Create table\n",
    "c.execute('CREATE TABLE COORDS (CITY_COUNTRY, LAT, LON)')\n",
    "conn.commit()\n",
    "coords_df.to_sql('COORDS', conn, if_exists='replace', index = True)\n",
    "\n",
    "# check if table in database is created\n",
    "\n",
    "c.execute('''  \n",
    "SELECT * FROM COORDS\n",
    "          ''')\n",
    "\n",
    "for row in c.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
