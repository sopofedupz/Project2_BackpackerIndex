{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set executable path and initialize Chrome browser\n",
    "executable_path = {\"executable_path\": \"chromedriver.exe\"}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the backpacker website\n",
    "url = \"https://www.priceoftravel.com/world-cities-by-price-backpacker-index/\"\n",
    "browser.visit(url)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# Find all cities in top list\n",
    "top_cities_html = browser.html\n",
    "top_cities_soup = bs(top_cities_html, \"html.parser\")\n",
    "\n",
    "top_cities = top_cities_soup.find('div', class_ = \"bpiidx_list\").find_all('a', href=True)\n",
    "\n",
    "top_cities_info = []\n",
    "places_list = []\n",
    "\n",
    "for city in range(0,len(top_cities)):\n",
    "        \n",
    "    city_state_name = top_cities[city].text.replace(\"\\n\",\" \").strip()\n",
    "    places_list.append(city_state_name)\n",
    "    \n",
    "    # get city and state name\n",
    "    city_name = city_state_name.split(\", \")[0]\n",
    "    country_name = city_state_name.split(\", \")[1]\n",
    "    \n",
    "    # get the links to each of the top cities page\n",
    "    top_city = top_cities[city]\n",
    "    top_cities_link = top_city.get_attribute_list('href')[0]\n",
    "    browser.visit(top_cities_link)\n",
    "    \n",
    "    # creating a dict\n",
    "    city_info_dict = {}\n",
    "    \n",
    "    #######################\n",
    "    # Scrape facts table\n",
    "    #######################\n",
    "    try:\n",
    "        # getting the city facts\n",
    "        browser_html = browser.html\n",
    "        browser_soup = bs(browser_html, \"html.parser\")\n",
    "        \n",
    "        population = browser_soup.find(\"table\", class_ = \"col city-facts\").find_all('td', class_ = \"white\")[0]\n",
    "        population = population.text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "        metro = browser_soup.find(\"table\", class_ = \"col city-facts\").find_all('td', class_ = \"white\")[1]\n",
    "        metro = metro.text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "        timezone = browser_soup.find(\"table\", class_ = \"col city-facts\").find_all('td', class_ = \"white\")[2]\n",
    "        timezone = timezone.text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "        currency = browser_soup.find(\"table\", class_ = \"col city-facts\").find_all('td', class_ = \"white\")[3]\n",
    "        currency = currency.text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "        airport = browser_soup.find(\"table\", class_ = \"col city-facts\").find_all('td', class_ = \"white\")[4]\n",
    "        airport = airport.text.replace(\"\\n\",\" \").strip()\n",
    "        \n",
    "        # Create a dict to store the information\n",
    "        city_facts = []\n",
    "        city_facts_dict = {}\n",
    "        city_facts_dict['city'] = city_name\n",
    "        city_facts_dict['country'] = country_name\n",
    "        city_facts_dict['population'] = population\n",
    "        city_facts_dict['metro_area'] = metro\n",
    "        city_facts_dict['timezone'] = timezone\n",
    "        city_facts_dict['currency'] = currency\n",
    "        city_facts_dict['airport'] = airport\n",
    "\n",
    "        # append dict to list\n",
    "        city_facts.append(city_facts_dict)       \n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    # add data to the larger dict\n",
    "    city_info_dict[\"city_facts\"] = city_facts\n",
    "                    \n",
    "    ################################\n",
    "    # Scrape transportation prices\n",
    "    ################################\n",
    "    \n",
    "    transport_list = []\n",
    "\n",
    "    try:\n",
    "        # Gather transportation information\n",
    "        \n",
    "        browser_html = browser.html\n",
    "        browser_soup = bs(browser_html, \"html.parser\")\n",
    "        \n",
    "        transport_table = browser_soup.find(\"table\", class_ = \"fcol fcol-padding\").find_all('tr', class_ = \"border no-pad\")\n",
    "\n",
    "        \n",
    "        for transport in range(0,len(transport_table)):\n",
    "            \n",
    "            # create an empty dict\n",
    "            transport_dict = {}\n",
    "        \n",
    "            # get transport mode/type\n",
    "            transport_mode = transport_table[transport].find('td', class_=\"white\")\n",
    "            transport_mode = transport_mode.text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "            # get transportation price\n",
    "            transport_price = transport_table[transport].find('td', class_=\"white2\")\n",
    "            transport_price = transport_price.text.replace(\"\\n\",\" \").strip()\n",
    "                       \n",
    "            # put everything in a dict\n",
    "            transport_dict['transport_mode'] = transport_mode\n",
    "            transport_dict['transport_price'] = transport_price\n",
    "\n",
    "            # append dict to the transport list\n",
    "            transport_list.append(transport_dict)\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "        \n",
    "    # add data to the larger dict\n",
    "    city_info_dict[\"transportation\"] = transport_list\n",
    "                            \n",
    "    ################################\n",
    "    # Scrape food and drink prices\n",
    "    ################################\n",
    "        \n",
    "    food_list = []\n",
    "    \n",
    "    # Gather food information\n",
    "    try:\n",
    "        browser_html = browser.html\n",
    "        browser_soup = bs(browser_html, \"html.parser\")\n",
    "        \n",
    "        food_table = browser_soup.find_all(\"table\", class_ = \"fcol fcol-padding\")[1]\n",
    "        food_table = food_table.find_all('td', class_ = \"white\")\n",
    "        \n",
    "        for food in range(0,len(food_table),3):  \n",
    "                \n",
    "            # create an empty dict\n",
    "            food_dict = {}\n",
    "\n",
    "            # get food type\n",
    "            food_type = food_table[food].text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "            # get description\n",
    "            food_desc = food_table[food+1].text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "            # get food price\n",
    "            food_price = food_table[food+2].text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "            # put everything in a dict\n",
    "            food_dict['food_type'] = food_type\n",
    "            food_dict['food_desc'] = food_desc\n",
    "            food_dict['food_price'] = food_price\n",
    "\n",
    "            # append dict to the food list\n",
    "            food_list.append(food_dict)\n",
    "    \n",
    "    except AttributeError:\n",
    "        pass\n",
    "        \n",
    "    # add data to the larger dict\n",
    "    city_info_dict[\"food\"] = food_list\n",
    "        \n",
    "    ########################################\n",
    "    # Scrape temperature & precipitation\n",
    "    ########################################\n",
    "    \n",
    "    temp_prcp_list = []\n",
    "    \n",
    "    try:\n",
    "        browser_html = browser.html\n",
    "        browser_soup = bs(browser_html, \"html.parser\")\n",
    "        \n",
    "        table = browser_soup.find(\"table\", class_ = \"center-table weather-tab\").find_all(\"td\")\n",
    "\n",
    "        # Gather temperature and precipitation information\n",
    "        for data in range(0,len(table),4):\n",
    "\n",
    "            month_dict = {}\n",
    "            month_list = []\n",
    "            hi_temp_list = []\n",
    "            lo_temp_list = []\n",
    "            prcp_list = []\n",
    "\n",
    "            # get month\n",
    "            month = table[data].text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "            # get high temp\n",
    "            hi_temp = table[data+1].text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "            # get low temp\n",
    "            lo_temp = table[data+2].text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "            # get precipitation in inches\n",
    "            prcp = table[data+3].text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "            # append the dicts to list\n",
    "            month_dict['month'] = month\n",
    "            month_dict['high_temp'] = hi_temp\n",
    "            month_dict['low_temp'] = lo_temp\n",
    "            month_dict['prcp_inch'] = prcp\n",
    "\n",
    "            temp_prcp_list.append(month_dict)\n",
    "     \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    # add data to the larger dict\n",
    "    city_info_dict[\"temp_prcp\"] = temp_prcp_list\n",
    "            \n",
    "    top_cities_info.append(city_info_dict)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "browser.quit()\n",
    "\n",
    "#top_cities_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cities_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
