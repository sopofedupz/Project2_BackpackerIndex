{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set executable path and initialize Chrome browser\n",
    "executable_path = {\"executable_path\": \"chromedriver.exe\"}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the backpacker website\n",
    "url = \"https://www.priceoftravel.com/world-cities-by-price-backpacker-index/\"\n",
    "browser.visit(url)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# Find all cities in top list\n",
    "top_cities_html = browser.html\n",
    "top_cities_soup = bs(top_cities_html, \"html.parser\")\n",
    "\n",
    "top_cities = top_cities_soup.find('div', class_ = \"bpiidx_list\").find_all('a', href=True)\n",
    "daily_total = top_cities_soup.find('div', class_ = \"bpiidx_list\").find_all('div', class_=\"bpidx price\")\n",
    "\n",
    "# create a dict for each set of information type\n",
    "city_facts_dict = {}\n",
    "transport_dict = {}\n",
    "food_drinks_dict = {}\n",
    "temp_prcp_dict = {}\n",
    "\n",
    "# create all the lists that we need to store the information\n",
    "places_list = []\n",
    "rank_list = []\n",
    "daily_total_list = []\n",
    "population_list = []\n",
    "metro_list = []\n",
    "timezone_list = []\n",
    "currency_list = []\n",
    "airport_list = []\n",
    "transport_city_list = []\n",
    "transport_mode_list = []\n",
    "transport_price_list = []\n",
    "food_city_list = []\n",
    "food_type_list = []\n",
    "food_desc_list = []\n",
    "food_price_list = []\n",
    "temp_prcp_cityList = []\n",
    "month_list = []\n",
    "high_temp_list = []\n",
    "low_temp_list = []\n",
    "prcp_inch_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in range(0,len(top_cities)):\n",
    "        \n",
    "    city_country_name = top_cities[city].text.replace(\"\\n\",\" \").strip()\n",
    "    places_list.append(city_country_name)\n",
    "    \n",
    "    # get daily total\n",
    "    city_daily_total = daily_total[city]\n",
    "    city_daily_total = city_daily_total.text.replace(\"\\n\",\" \").strip()\n",
    "    daily_total_list.append(city_daily_total)\n",
    "\n",
    "    # get the links to each of the top cities page\n",
    "    top_city = top_cities[city]\n",
    "    top_cities_link = top_city.get_attribute_list('href')[0]\n",
    "    browser.visit(top_cities_link)\n",
    "\n",
    "    #######################\n",
    "    # Scrape facts table\n",
    "    #######################\n",
    "    try:\n",
    "        # getting the city facts\n",
    "        browser_html = browser.html\n",
    "        browser_soup = bs(browser_html, \"html.parser\")\n",
    "        \n",
    "        population = browser_soup.find(\"table\", class_ = \"col city-facts\").find_all('td', class_ = \"white\")[0]\n",
    "        population = population.text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "        metro = browser_soup.find(\"table\", class_ = \"col city-facts\").find_all('td', class_ = \"white\")[1]\n",
    "        metro = metro.text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "        timezone = browser_soup.find(\"table\", class_ = \"col city-facts\").find_all('td', class_ = \"white\")[2]\n",
    "        timezone = timezone.text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "        currency = browser_soup.find(\"table\", class_ = \"col city-facts\").find_all('td', class_ = \"white\")[3]\n",
    "        currency = currency.text.replace(\"\\n\",\" \").strip()\n",
    "\n",
    "        airport = browser_soup.find(\"table\", class_ = \"col city-facts\").find_all('td', class_ = \"white\")[4]\n",
    "        airport = airport.text.replace(\"\\n\",\" \").strip()\n",
    "          \n",
    "    except AttributeError:\n",
    "        population = \"\"\n",
    "        metro = \"\"\n",
    "        timezone = \"\"\n",
    "        currency = \"\"\n",
    "        airport = \"\"\n",
    "\n",
    "    # append data to lists\n",
    "    rank_list.append(city+1)\n",
    "    population_list.append(population)\n",
    "    metro_list.append(metro)\n",
    "    timezone_list.append(timezone)\n",
    "    currency_list.append(currency)\n",
    "    airport_list.append(airport)\n",
    "    \n",
    "    ################################\n",
    "    # Scrape transportation prices\n",
    "    ################################\n",
    "\n",
    "    try:\n",
    "        # Gather transportation information\n",
    "        \n",
    "        browser_html = browser.html\n",
    "        browser_soup = bs(browser_html, \"html.parser\")\n",
    "        \n",
    "        transport_table = browser_soup.find(\"table\", class_ = \"fcol fcol-padding\").find_all('tr', class_ = \"border no-pad\")\n",
    "        \n",
    "        for transport in range(0,len(transport_table)):\n",
    "            \n",
    "            # get transport mode/type\n",
    "            transport_mode = transport_table[transport].find('td', class_=\"white\")\n",
    "            transport_mode = transport_mode.text.replace(\"\\n\",\" \").strip()\n",
    "            transport_mode_list.append(transport_mode)\n",
    "\n",
    "            # get transportation price\n",
    "            transport_price = transport_table[transport].find('td', class_=\"white2\")\n",
    "            transport_price = transport_price.text.replace(\"\\n\",\" \").strip()\n",
    "            transport_price_list.append(transport_price)\n",
    "            \n",
    "            # get country list\n",
    "            transport_city_list.append(city_country_name)\n",
    "                                           \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    ################################\n",
    "    # Scrape food and drink prices\n",
    "    ################################\n",
    "    \n",
    "    # Gather food information\n",
    "    try:\n",
    "        browser_html = browser.html\n",
    "        browser_soup = bs(browser_html, \"html.parser\")\n",
    "        \n",
    "        food_table = browser_soup.find_all(\"table\", class_ = \"fcol fcol-padding\")[1]\n",
    "        food_table = food_table.find_all('td', class_ = \"white\")\n",
    "        \n",
    "        for food in range(0,len(food_table),3):  \n",
    "\n",
    "            # get food type\n",
    "            food_type = food_table[food].text.replace(\"\\n\",\" \").strip()\n",
    "            food_type_list.append(food_type)\n",
    "\n",
    "            # get description\n",
    "            food_desc = food_table[food+1].text.replace(\"\\n\",\" \").strip()\n",
    "            food_desc_list.append(food_desc)\n",
    "\n",
    "            # get food price\n",
    "            food_price = food_table[food+2].text.replace(\"\\n\",\" \").strip()\n",
    "            food_price_list.append(food_price)\n",
    "            \n",
    "            # get country list\n",
    "            food_city_list.append(city_country_name)\n",
    "\n",
    "    except AttributeError:\n",
    "        pass\n",
    "        \n",
    "    ########################################\n",
    "    # Scrape temperature & precipitation\n",
    "    ########################################\n",
    "    \n",
    "    try:\n",
    "        browser_html = browser.html\n",
    "        browser_soup = bs(browser_html, \"html.parser\")\n",
    "        \n",
    "        table = browser_soup.find(\"table\", class_ = \"center-table weather-tab\").find_all(\"td\")\n",
    "\n",
    "        # Gather temperature and precipitation information\n",
    "        for data in range(0,len(table),4):\n",
    "\n",
    "            # get month\n",
    "            month = table[data].text.replace(\"\\n\",\" \").strip()\n",
    "            month_list.append(month)\n",
    "\n",
    "            # get high temp\n",
    "            hi_temp = table[data+1].text.replace(\"\\n\",\" \").strip()\n",
    "            high_temp_list.append(hi_temp)\n",
    "\n",
    "            # get low temp\n",
    "            lo_temp = table[data+2].text.replace(\"\\n\",\" \").strip()\n",
    "            low_temp_list.append(lo_temp)\n",
    "\n",
    "            # get precipitation in inches\n",
    "            prcp = table[data+3].text.replace(\"\\n\",\" \").strip()\n",
    "            prcp_inch_list.append(prcp)\n",
    "            \n",
    "            # get country list\n",
    "            temp_prcp_cityList.append(city_country_name)\n",
    "\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# put into a dict\n",
    "###################\n",
    "\n",
    "# city facts table\n",
    "city_facts_dict['city_country'] = places_list\n",
    "city_facts_dict['rank'] = rank_list \n",
    "city_facts_dict['daily_total_value'] = daily_total_list\n",
    "city_facts_dict['population'] = population_list\n",
    "city_facts_dict['metro'] = metro_list\n",
    "city_facts_dict['timezone'] = timezone_list\n",
    "city_facts_dict['currency'] = currency_list\n",
    "city_facts_dict['airport'] = airport_list\n",
    "\n",
    "# transportation table\n",
    "transport_dict['city_country'] = transport_city_list\n",
    "transport_dict['transport_mode'] = transport_mode_list\n",
    "transport_dict['transport_price'] = transport_price_list\n",
    "\n",
    "# food and drinks table\n",
    "food_drinks_dict['city_country'] = food_city_list\n",
    "food_drinks_dict['food_drinks_type'] = food_type_list\n",
    "food_drinks_dict['food_drinks_desc'] = food_desc_list\n",
    "food_drinks_dict['food_drinks_price'] = food_price_list\n",
    "\n",
    "# temperature and precipitation table\n",
    "temp_prcp_dict['city_country'] = temp_prcp_cityList\n",
    "temp_prcp_dict['month'] = month_list\n",
    "temp_prcp_dict['high_temp'] = high_temp_list\n",
    "temp_prcp_dict['low_temp'] = low_temp_list\n",
    "temp_prcp_dict['prcp_inch'] = prcp_inch_list\n",
    "\n",
    "##################################\n",
    "# put data into pandas dataframe\n",
    "##################################\n",
    "city_facts_df = pd.DataFrame.from_dict(city_facts_dict)\n",
    "transport_df = pd.DataFrame.from_dict(transport_dict)\n",
    "food_drinks_df = pd.DataFrame.from_dict(food_drinks_dict)\n",
    "temp_prcp_df = pd.DataFrame.from_dict(temp_prcp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataframe\n",
    "city_facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataframe\n",
    "transport_df.groupby(['city_country']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_drinks_df.groupby(['city_country']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_prcp_df.groupby(['city_country']).count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
